---
title: "Autopilot - El Cerebro: Configurando Gemini y CrewAI para leer mi blog"
date: 2025-12-31
draft: false
categories: ["Ingenier√≠a de Software", "IA Generativa", "Python"]
tags: ["CrewAI", "Gemini API", "Backend", "Clean Code", "Automatizaci√≥n"]
image: "cover.png"
description: "Segundo cap√≠tulo de Proyecto Autopilot. Abrimos el IDE para conectar Python con Gemini Flash y crear nuestro primer Agente Analista capaz de entender c√≥digo Markdown."
summary: "Un script que lee archivos es f√°cil. Un script que 'entiende' la tecnolog√≠a es otra historia. En este post configuramos el entorno Python, solucionamos los errores de integraci√≥n de CrewAI y logramos que Gemini Flash extraiga 'oro puro' de nuestros posts en Markdown."
---

En el [Post 1: La Estrategia]({{< ref "ia_agents_part1" >}}), promet√≠ que no usar√≠a herramientas de terceros para gestionar mis redes sociales. Promet√≠ construir un "ej√©rcito de agentes".

Hoy, dejamos el PowerPoint y abrimos el IDE. Vamos a construir el **Cerebro** del sistema.

El objetivo de hoy es t√©cnico y concreto: crear un script en Python que sea capaz de leer un archivo `.md` de mi repositorio local, "leerlo" como lo har√≠a un ingeniero senior, y devolverme un an√°lisis estructurado en JSON.

![Imagen conceptual del proyecto - El cerebro](autopilot_brain.png)

## El Stack Tecnol√≥gico: Velocidad sobre Potencia Bruta

Para esta tarea, he tomado dos decisiones de arquitectura:

1.  **El Orquestador: CrewAI.** Necesito algo que maneje "Agentes" y "Tareas", no solo cadenas de texto. CrewAI me permite definir *roles* (qui√©n eres) y *goals* (qu√© quieres), lo cual es vital para los siguientes pasos.
2.  **El Modelo: Google Gemini Flash.** Al principio intent√© usar el modelo m√°s potente (Pro), pero me di cuenta de un error de principiante: para tareas de lectura masiva y extracci√≥n de datos, no necesitas al fil√≥sofo, necesitas al bibliotecario r√°pido. Flash es mucho m√°s r√°pido, barato (gratis en el tier actual) y tiene una ventana de contexto gigantesca.

## Paso 1: Higiene del Repositorio (Clean Monorepo)

Antes de escribir c√≥digo, hay que organizar la casa. Mi blog est√° hecho en Hugo, y no quiero ensuciar la carpeta del sitio web con scripts de Python.

He optado por una estructura de "Monorepo Limpio". He creado una carpeta `autopilot` en la ra√≠z del proyecto que act√∫a como un m√≥dulo independiente.

```text
datalaria/
‚îú‚îÄ‚îÄ content/           <-- Mis posts en Markdown (Hugo)
‚îú‚îÄ‚îÄ themes/
‚îú‚îÄ‚îÄ autopilot/         <-- EL NUEVO CEREBRO üß†
‚îÇ   ‚îú‚îÄ‚îÄ .env           <-- ¬°OJO! Aqu√≠ van las claves (Ignorado por Git)
‚îÇ   ‚îú‚îÄ‚îÄ main.py        <-- El punto de entrada
‚îÇ   ‚îî‚îÄ‚îÄ src/           <-- L√≥gica de Agentes y Tareas
‚îî‚îÄ‚îÄ .gitignore         <-- Configurado para proteger mis secretos
```

> **Lecci√≥n aprendida:** Configura tu `.gitignore` antes de hacer el primer commit. Si subes tu API Key a GitHub por error, los bots tardar√°n segundos en encontrarla o peor a√∫n, puede que te encuentres con costes indeseados de otros usuarios que hayan encontrado tu API Key.

## Paso 2: El C√≥digo (Manos a la obra)

El coraz√≥n de este sistema no es `main.py`, sino c√≥mo definimos al agente. Usando la librer√≠a `crewai` y `langchain_google_genai`, defin√≠ a mi primer empleado digital: **"El Analista"**.

### El Problema de la "Obsesi√≥n con OpenAI"

Aqu√≠ me top√© con el primer muro. CrewAI est√° dise√±ado por defecto para buscar una API Key de OpenAI (GPT-4). Aunque yo configur√© Gemini, el script fallaba con el error:

`ValueError: OPENAI_API_KEY is required`

La soluci√≥n fue forzar expl√≠citamente el LLM (Large Language Model) dentro de la definici√≥n del agente. As√≠ se ve el c√≥digo en `src/agents.py`:

```python
from crewai import Agent
from langchain_google_genai import ChatGoogleGenerativeAI
import os

class BlogAgents:
    def __init__(self):
        # Configuramos Gemini Flash expl√≠citamente
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            verbose=True,
            temperature=0.2, # Baja temperatura = M√°s anal√≠tico, menos creativo
            google_api_key=os.getenv("GOOGLE_API_KEY")
        )

    def analyst_agent(self):
        return Agent(
            role='Senior Tech Editor & Data Analyst',
            goal='Analyze raw content to extract structured insights',
            backstory='You are a veteran tech editor...',
            allow_delegation=False,
            llm=self.llm  # <--- ESTA L√çNEA ES CR√çTICA. Si la quitas, buscar√° OpenAI.
        )
```

## Paso 3: El Prompt de Ingenier√≠a (JSON Mode)

Para que esto sea √∫til, el agente no puede simplemente "charlar" sobre el art√≠culo. Necesito datos que pueda procesar computacionalmente despu√©s.

En `src/tasks.py`, defin√≠ la tarea con instrucciones estrictas de salida. No us√© el "JSON Mode" nativo de la API (que a veces es complejo de configurar), sino que confi√© en la capacidad de instrucci√≥n del modelo:

> "OUTPUT FORMAT: Return ONLY a valid JSON object with keys: summary, target_audience, tech_stack, key_takeaways, marketing_hooks."

## El Resultado: ¬°Funciona!

Ejecut√© el script contra uno de mis art√≠culos t√©cnicos m√°s densos (sobre procesos S&OP). Ten√≠a miedo de que el modelo alucinara o se perdiera en el texto.

El resultado en la terminal fue este JSON limpio:

```json
{
  "summary": "This post demonstrates how Generative AI bridges the gap between complex business narratives and technical execution...",
  "target_audience": "Business Analysts, Industrial Engineers, Operations Managers...",
  "tech_stack": [
    "Generative AI (LLMs)",
    "BPMN 2.0",
    "Mermaid.js",
    "Gemini API"
  ],
  "marketing_hooks": [
    "Stop drowning in dense business requirements! üöÄ Learn how to use AI to turn messy narratives into professional BPMN diagrams...",
    "Documentation as Code is here. üíª See how LLMs can generate Mermaid.js diagrams..."
  ]
}
```

Es impresionante. El modelo no solo resumi√≥ el texto, sino que entendi√≥ el **contexto profundo**: identific√≥ que el art√≠culo hablaba de "Mermaid.js" y "BPMN" y gener√≥ ganchos de marketing ("marketing_hooks") que realmente suenan a algo que yo escribir√≠a en Twitter.

## ¬øQu√© sigue?

Ya tenemos el **Cerebro** (`autopilot`) capaz de leer y entender lo que escribo en `content`. Los datos est√°n estructurados y listos.

Pero un JSON no consigue likes.

En el pr√≥ximo post, vamos a construir a **Los Creativos**. Usaremos estos datos para alimentar a dos nuevos agentes con personalidades opuestas: un experto en viralidad para Twitter y un estratega corporativo para LinkedIn. Y veremos c√≥mo el *Prompt Engineering* puede cambiar dr√°sticamente el tono de una IA.

üëâ **C√≥digo Fuente:** Puedes ver el c√≥digo de este m√≥dulo en la carpeta `/autopilot` del [repositorio de Datalaria en GitHub](https://github.com/Dalaez/datalaria-website).