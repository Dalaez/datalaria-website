---
title: "Autopilot - Ctrl: AuditorÃ­a de Contenido IA con GitHub Copilot CLI"
date: 2026-02-01
draft: false
categories: ["DevOps", "Python", "AI"]
tags: ["devchallenge", "githubchallenge", "cli", "githubcopilot", "Copilot CLI", "Content Audit", "Automation"]
image: "cover.png"
description: "Construyo autopilot-ctrl, una CLI que usa GitHub Copilot CLI para auditar y mejorar automÃ¡ticamente el contenido generado por IA antes de publicarlo en redes sociales."
summary: "Cuando la IA genera contenido para redes sociales, Â¿cÃ³mo sabemos si es bueno? ConstruÃ­ autopilot-ctrl, una herramienta que usa GitHub Copilot CLI para evaluar la calidad del contenido antes de publicar."
---

*This is a submission for the [GitHub Copilot CLI Challenge](https://dev.to/challenges/github-2026-01-21)*

## What I Built

**autopilot-ctrl** es una herramienta de lÃ­nea de comandos que audita contenido de redes sociales generado por IA antes de publicarlo. PiÃ©nsalo como un "quality gate" para tu pipeline de contenido.

### El Problema

Mi blog tiene un sistema de autopilot que genera automÃ¡ticamente posts para Twitter, LinkedIn y Newsletter cada vez que publico un artÃ­culo. Funciona genial... la mayorÃ­a del tiempo. Pero a veces la IA produce:

- ğŸ¦ Tweets genÃ©ricos sin gancho
- ğŸ’¼ Posts de LinkedIn sin estructura
- ğŸ“§ Newsletters que revelan demasiado (o muy poco)

Necesitaba una forma de **evaluar la calidad ANTES de publicar** y, si algo no pasaba el corte, mejorarlo automÃ¡ticamente.

### La SoluciÃ³n

**autopilot-ctrl** usa GitHub Copilot CLI para:

1. **Auditar** contenido contra criterios especÃ­ficos por plataforma
2. Asignar un **score de calidad** (0-10)
3. **Identificar problemas** especÃ­ficos
4. **Generar versiones mejoradas** del contenido que falla

```
                               ğŸ“Š Audit Results                                
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Platform    â”‚  Score  â”‚  Status   â”‚ Issues                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Twitter     â”‚ 3.0/10  â”‚ [XX] FAIL â”‚ No hook, missing hashtags               â”‚
â”‚ Linkedin    â”‚ 7.0/10  â”‚ [OK] PASS â”‚ -                                       â”‚
â”‚ Newsletter  â”‚ 8.0/10  â”‚ [OK] PASS â”‚ -                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Demo

{{< youtube KNjx5IB8jr8 >}}

**Comandos disponibles:**

```bash
# Verificar que Copilot CLI estÃ¡ instalado
python -m ctrl check

# Auditar contenido
python -m ctrl audit content.json

# Arreglar contenido que falla
python -m ctrl fix content.json --apply
```

**Screenshots del flujo:**

![1. IntroducciÃ³n a Autopilot-Ctrl](PS_Autopilot_Intro.png)

![2. VerificaciÃ³n de Copilot CLI](PS_Autopilot_Check.png)

![3. Contenido de ejemplo](PS_Autopilot_SampleContent.png)

![4. Resultados de la auditorÃ­a](PS_Autopilot_Audit.png)

![5. Contenido mejorado por Copilot](PS_Autopilot_Fix.png)

**CÃ³digo fuente:** [github.com/Dalaez/datalaria/autopilot/ctrl](https://github.com/Dalaez/datalaria-website)

## My Experience with GitHub Copilot CLI

### ğŸš€ CÃ³mo UsÃ© Copilot CLI

La magia de autopilot-ctrl estÃ¡ en cÃ³mo integra Copilot CLI en modo no interactivo:

```python
# auditor.py
result = subprocess.run(
    ['copilot', '-s', '--no-ask-user', '-p', prompt],
    capture_output=True,
    text=True,
    timeout=60,
    encoding='utf-8'
)
```

Cada auditorÃ­a envÃ­a un prompt estructurado a Copilot CLI y parsea la respuesta natural para extraer:
- Score numÃ©rico (ej: "Rating: 7/10")
- Lista de issues (ej: "No engagement", "Generic hook")
- Sugerencias de mejora

### ğŸ’¡ Lo Que AprendÃ­

1. **El orden de las flags importa**: `-p` DEBE ser el Ãºltimo argumento
2. **Prompts simples funcionan mejor**: Los prompts largos y estructurados en modo no interactivo devuelven respuestas vacÃ­as
3. **Copilot responde en lenguaje natural**: Tuve que crear parsers flexibles para extraer datos de respuestas como "**Rating: 7/10**"

### âš¡ El Impacto en Mi Workflow

Antes de autopilot-ctrl, revisaba manualmente cada post generado. Ahora:

1. `git push` â†’ Autopilot genera contenido
2. `python -m ctrl audit generated_content.json` â†’ Copilot evalÃºa
3. Si algo falla â†’ `python -m ctrl fix` genera mejoras
4. Contenido aprobado â†’ Se publica automÃ¡ticamente

**Tiempo ahorrado**: ~15 minutos por publicaciÃ³n.

### ğŸ› ï¸ Stack TÃ©cnico

- **Python + Click**: Framework CLI
- **Rich**: UI de terminal con tablas y colores
- **GitHub Copilot CLI**: Motor de evaluaciÃ³n IA
- **YAML configs**: Prompts personalizables por plataforma

---

## ConclusiÃ³n

autopilot-ctrl demuestra que GitHub Copilot CLI no es solo para generar cÃ³digo. Es una herramienta poderosa para **integrar IA en cualquier pipeline** - en este caso, evaluaciÃ³n de calidad de contenido.

Si tienes un sistema que genera contenido automÃ¡ticamente, considera aÃ±adir un "quality gate" con Copilot CLI. Tu audiencia (y tus mÃ©tricas de engagement) te lo agradecerÃ¡n.

**Â¿Preguntas?** DÃ©jalas en los comentarios ğŸ‘‡

---

*Este post es parte de la serie [Proyecto Autopilot](https://datalaria.com/es/posts/ia_agents_part1/), donde documento cÃ³mo automatizo la creaciÃ³n y publicaciÃ³n de contenido usando IA.*
