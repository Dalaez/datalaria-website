---
title: "S&OP: Por quÃ© tu Excel te miente (y cÃ³mo interrogarlo con Python)"
date: 2026-02-14
draft: false
categories: ["IngenierÃ­a de S&OP", "Data Engineering", "Python"]
tags: ["Supply Chain", "S&OP", "Supabase", "Pandas", "Z-Score"]
author: "Datalaria"
description: "Dejemos de limpiar datos a mano. En este primer capÃ­tulo de la serie IngenierÃ­a de S&OP, automatizamos la higiene de datos usando Python, Supabase y EstadÃ­stica para detectar la verdad oculta tras el ruido."
image: "cover.png"
---

En las reuniones de S&OP (Sales & Operations Planning), a menudo se discute sobre opiniones en lugar de hechos. *"Creo que venderemos mÃ¡s"*, *"El mes pasado fue raro"*. 

El problema raÃ­z no es la falta de visiÃ³n comercial, es la **falta de integridad en la seÃ±al**.

La mayorÃ­a de las cadenas de suministro se gestionan sobre hojas de cÃ¡lculo que aceptan cualquier cosa: fechas como texto, espacios en blanco, y errores de dedo que convierten un pedido de 100 unidades en 100.000. Cuando alimentas tu algoritmo de predicciÃ³n con esa "basura", obtienes basura amplificada (El efecto *Bullwhip* financiero).

Hoy iniciamos la serie **IngenierÃ­a del S&OP**. No vamos a hablar de teorÃ­a; vamos a construir una arquitectura de datos que audite tu negocio automÃ¡ticamente.

![Imagen IngenierÃ­a del S&OP](cover.png)

## El Problema: Signal-to-Noise Ratio

En telecomunicaciones (mi background original), el ruido es cualquier interferencia que corrompe la seÃ±al. En Supply Chain, el "ruido" son los datos sucios.

Si no filtras el ruido antes de planificar la demanda, estÃ¡s **inmovilizando capital**. Un *outlier* no detectado es dinero en llamas. Si tu algoritmo ve un pico falso de 100.000 unidades, ordenarÃ¡ materia prima que no necesitas, quemando caja y ocupando espacio en almacÃ©n. La higiene de datos no es 'limpieza', es protecciÃ³n del margen operativo.

### La Evidencia Visual

Antes de ver una sola lÃ­nea de cÃ³digo, mira la diferencia entre lo que tu ERP exporta (arriba) y la realidad estadÃ­stica de tu demanda (abajo).

![Impacto de la Higiene de Datos](sop_impact_chart.png)
*Arriba: Datos crudos con errores humanos. Abajo: La seÃ±al limpia lista para algoritmos de IA.*

## La SoluciÃ³n: Arquitectura de "VÃ¡lvula de Calidad"

Para solucionar esto, aplicamos **First Principles Thinking**. No necesitamos "tener mÃ¡s cuidado" con el Excel. Necesitamos un sistema que matemÃ¡ticamente **prohÃ­ba** la entrada de datos sucios a nuestra "Verdad Ãšnica".

Hemos diseÃ±ado un pipeline automatizado con el siguiente stack:

* **Cerebro:** Python (Pandas + Scipy) para la lÃ³gica estadÃ­stica.
* **AlmacÃ©n:** Supabase (PostgreSQL) como la "Verdad Ãšnica".
* **Agente:** Un script que se ejecuta automÃ¡ticamente ante nuevos archivos.

### El CÃ³digo: EstadÃ­stica > IntuiciÃ³n

No usamos reglas fijas ("si es mayor que 1000, borra"). Usamos estadÃ­stica. Implementamos el **Z-Score**, que mide cuÃ¡ntas desviaciones estÃ¡ndar se aleja un dato de la media.

Si una venta tiene un `Z-Score > 3` (estÃ¡ a mÃ¡s de 3 sigmas de la normalidad), es matemÃ¡ticamente improbable que sea comportamiento estÃ¡ndar. El sistema no lo borra (podrÃ­a ser una venta real), pero lo **marca para auditorÃ­a** y lo excluye de la predicciÃ³n automÃ¡tica.

*Nota*: Usamos Z-Score asumiendo normalidad para simplificar este ejemplo. En escenarios de producciÃ³n con demanda intermitente, utilizamos mÃ©todos como IQR (Interquartile Range) o MAD (Median Absolute Deviation) que son mÃ¡s robustos ante distribuciones no gaussianas.

AquÃ­ estÃ¡ la lÃ³gica central de nuestra clase `SupplyChainSanitizer`:

```python
def detect_outliers_zscore(self, threshold=3):
    """
    Detecta anomalÃ­as estadÃ­sticas usando Z-Score.
    No borramos la fila (pÃ©rdida de info), la etiquetamos.
    """
    # Calculamos la desviaciÃ³n estÃ¡ndar de la seÃ±al
    z_scores = np.abs(stats.zscore(self.df['qty']))
    
    # Marcamos lo que es matemÃ¡ticamente sospechoso
    self.df['is_outlier'] = z_scores > threshold
    return self
```

## Open Kitchen: PruÃ©balo tÃº mismo

Como ingeniero, desconfÃ­o de lo que no puedo ejecutar. Por eso, he aislado la lÃ³gica de limpieza en un [Notebook interactivo en Colab](https://colab.research.google.com/drive/16HGhPhUx4NGKnXHrtsF_xlJqU5qlnUVy?usp=sharing).

No necesitas instalar Python ni configurar bases de datos. He preparado un entorno efÃ­mero donde puedes:

* Generar un dataset de ventas corrupto (simulado).
* Ejecutar el motor de limpieza `SupplyChainSanitizer`.
* Ver cÃ³mo el algoritmo detecta y separa el ruido.

Haz clic en el botÃ³n, dale a "Play" en las celdas y observa la ingenierÃ­a de datos en acciÃ³n.

## Arquitectura de ProducciÃ³n (Behind the Scenes)

Para los perfiles tÃ©cnicos interesados en cÃ³mo esto escala en una empresa real (Datalaria Core):

* **Ingesta:** Los CSVs se suben a un Bucket privado en Supabase Storage o en una Base de datos local.
* **Trigger:** Un worker de Python detecta el archivo.
* **Proceso:** Ejecuta la limpieza en memoria (Docker Container).
* **Persistencia:** Los datos limpios se inyectan en PostgreSQL usando Row Level Security (RLS) para asegurar que nadie pueda alterar el histÃ³rico financiero manualmente.

> **Nota de Seguridad:** En producciÃ³n, nunca conectamos scripts con permisos de superusuario. Usamos Service Roles especÃ­ficos y polÃ­ticas RLS estrictas para asegurar la integridad de la cadena de suministro.

### VisualizaciÃ³n del Flujo de Datos

El siguiente diagrama muestra cÃ³mo los datos "sucios" pasan por nuestra **VÃ¡lvula de Calidad** antes de llegar a la Verdad Ãšnica:

{{< mermaid >}}
flowchart LR
    subgraph ORIGEN["ğŸ“‚ Origen"]
        A["CSV del ERP<br/>(Datos Sucios)"]
    end

    subgraph PIPELINE["ğŸ§  VÃ¡lvula de Calidad (Python)"]
        B["structural_clean()<br/>Fechas Â· Nulos Â· Duplicados"]
        C["detect_outliers()<br/>Z-Score Ïƒ > 3"]
        D["get_audit_report()<br/>MÃ©tricas de Higiene"]
    end

    subgraph DESTINO["ğŸ—„ï¸ Verdad Ãšnica"]
        E[("Supabase<br/>PostgreSQL")]
        F["Datos Limpios<br/>(SeÃ±al Pura)"]
        G["Outliers Marcados<br/>(Para AuditorÃ­a)"]
    end

    A --> B --> C --> D
    D --> E
    E --> F
    E --> G

    style A fill:#ff6b6b,stroke:#c0392b,color:#fff
    style F fill:#2ecc71,stroke:#27ae60,color:#fff
    style G fill:#f39c12,stroke:#d35400,color:#fff
    style E fill:#3498db,stroke:#2980b9,color:#fff
{{< /mermaid >}}

**Leyenda:**
- ğŸ”´ **Rojo:** Datos crudos con ruido (el problema)
- ğŸŸ¢ **Verde:** SeÃ±al limpia lista para predicciÃ³n
- ğŸŸ  **Naranja:** AnomalÃ­as etiquetadas para revisiÃ³n humana
- ğŸ”µ **Azul:** AlmacÃ©n centralizado (Supabase)

## Siguiente Paso: PredicciÃ³n CientÃ­fica

Ahora que tenemos una base de datos limpia (una seÃ±al pura), estamos listos para mirar al futuro.

En el prÃ³ximo capÃ­tulo de la serie, conectaremos esta tabla limpia con **Facebook Prophet** para generar previsiones de demanda probabilÃ­sticas, abandonando para siempre las medias mÃ³viles simples de Excel.

SuscrÃ­bete para recibir el CapÃ­tulo 2: *"Demand Planning: De la AdivinaciÃ³n a la Probabilidad"*.